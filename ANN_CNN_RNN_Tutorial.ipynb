{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ik0rBMWnVJqi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "xkI4IosyWh39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transforms"
      ],
      "metadata": {
        "id": "2AeX3nBQVMLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- 设置设备和初始化模型 -----------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')"
      ],
      "metadata": {
        "id": "bpchN_3bVbLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- 超参数 -----------------\n",
        "batch_size = 16\n",
        "num_epochs = 25\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "-J0_lrrMVO5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- 数据加载 -----------------\n",
        "# 定义数据预处理：转换为 Tensor 并标准化\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])"
      ],
      "metadata": {
        "id": "_PEcKgIVVR7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 下载并加载 MNIST 训练和测试数据集\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "mKXaXlAwVUiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- 定义简单的 ANN 模型 -----------------\n",
        "class SimpleANN(nn.Module):\n",
        "    def __init__(self, input_size=28*28, hidden_size=256, num_classes=10):\n",
        "        super(SimpleANN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 将输入展平 (B, 1, 28, 28) -> (B, 28*28)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "Imw3OXtlVW2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- 定义简单的 CNN 模型 -----------------\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # 第一个卷积层：输入 1 通道，输出 32 通道，卷积核 3x3，padding 保持尺寸\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        # 第二个卷积层：输入 32 通道，输出 64 通道\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # 下采样因子为2\n",
        "\n",
        "        # 全连接层：假设输入图片为28x28，经过两次池化后尺寸变为7x7\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 卷积层1 -> BatchNorm -> ReLU -> 池化\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        # 卷积层2 -> BatchNorm -> ReLU -> 池化\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        # 展平\n",
        "        x = x.view(x.size(0), -1)\n",
        "        # 全连接层\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Hn5Lc2Zk1Wy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- 定义简单的 RNN 模型 -----------------\n",
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_size=28, hidden_size=256, num_layers=2, num_classes=10):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "        # 使用 nn.RNN，采用 tanh 激活函数，设置 batch_first=True\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, nonlinearity='tanh')\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x 的形状: (batch, 1, 28, 28)\n",
        "        # 将图像转换为序列：去掉 channel 维度，得到 (batch, 28, 28)\n",
        "        x = x.squeeze(1)\n",
        "        # 传入 RNN：输出 out 的形状为 (batch, 28, hidden_size)\n",
        "        out, _ = self.rnn(x)\n",
        "        # 取最后一个时间步的输出作为整个序列的表示 (batch, hidden_size)\n",
        "        out = out[:, -1, :]\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "bjM-oeVr-aDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleANN().to(device)\n",
        "#model = SimpleCNN(num_classes=10).to(device)\n",
        "#model = SimpleRNN(num_classes=10).to(device)"
      ],
      "metadata": {
        "id": "NJLQAQxXVd72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- 定义损失函数和优化器 -----------------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "ORrlsnAXVgIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- 训练循环 -----------------\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # 使用 tqdm 包装 train_loader，显示进度条\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\", dynamic_ncols=True)\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(progress_bar):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # 更新进度条后缀信息：显示当前 batch 的 loss\n",
        "        progress_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "XVjDfrctViVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- 模型评估 -----------------\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "tm9LQS-zVkww"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}